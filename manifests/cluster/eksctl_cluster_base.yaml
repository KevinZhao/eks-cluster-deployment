apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: ${CLUSTER_NAME}
  region: ${AWS_DEFAULT_REGION}
  version: "${K8S_VERSION}"
  tags:
    cluster-autoscaler: enabled

# Kubernetes 网络配置
kubernetesNetworkConfig:
  serviceIPv4CIDR: "${SERVICE_IPV4_CIDR}"

# 使用已经存在的vpc
vpc:
  id: "${VPC_ID}"
  subnets:
    private:
      ${AZ_A}:
        id: "${PRIVATE_SUBNET_A}"
      ${AZ_B}:
        id: "${PRIVATE_SUBNET_B}"
      ${AZ_C}:
        id: "${PRIVATE_SUBNET_C}"
    public:
      ${AZ_A}:
        id: "${PUBLIC_SUBNET_A}"
      ${AZ_B}:
        id: "${PUBLIC_SUBNET_B}"
      ${AZ_C}:
        id: "${PUBLIC_SUBNET_C}"
  clusterEndpoints:
    privateAccess: true
    publicAccess: false

accessConfig:
  authenticationMode: API_AND_CONFIG_MAP

# IAM 配置 - 使用 Pod Identity
iam:
  withOIDC: false

# 节点组配置
# 系统节点组，主要运行aws-load-balancer-controller coredns cluster-autoscaler等组件
managedNodeGroups:
  - name: eks-utils
    instanceType: m7i.large
    amiFamily: AmazonLinux2023
    desiredCapacity: 3
    minSize: 3
    maxSize: 6
    volumeSize: 50
    volumeType: gp3
    # Additional data disk for containerd
    additionalVolumes:
      - volumeName: "/dev/sdz"
        volumeSize: 100
        volumeType: gp3
    # Mount data disk to /var/lib/containerd using LVM with rsync migration
    preBootstrapCommands:
      - |
        set -euxo pipefail
        systemctl stop containerd || true

        # Auto-detect EBS data disk (exclude root disk nvme0n1)
        DISK=$$(lsblk -dpno NAME | grep nvme | grep -v nvme0n1 | head -1)
        if [ -z "$$DISK" ]; then
          echo "No data disk found, skip LVM setup"
          systemctl start containerd
          exit 0
        fi

        echo "Found data disk: $$DISK"

        # Check if LVM already configured
        if vgs vg_data &>/dev/null; then
          echo "LVM already configured"
        else
          # Install lvm2 (not installed by default on AL2023)
          dnf install -y lvm2

          # Create LVM
          pvcreate "$$DISK"
          vgcreate vg_data "$$DISK"
          lvcreate -l 100%VG -n lv_containerd vg_data
          mkfs.xfs /dev/vg_data/lv_containerd
        fi

        # Mount LV to temporary directory and migrate data
        TEMP_MOUNT="/mnt/runtime/containerd"
        mkdir -p "$$TEMP_MOUNT"

        echo "Mounting LV to temporary directory: $$TEMP_MOUNT"
        mount /dev/vg_data/lv_containerd "$$TEMP_MOUNT"

        echo "Copying containerd data (including cached images) from AMI..."
        rsync -aHAX /var/lib/containerd/ "$$TEMP_MOUNT/"

        echo "Unmounting temporary directory"
        umount "$$TEMP_MOUNT"

        echo "Mounting LV to final destination: /var/lib/containerd"
        mount /dev/vg_data/lv_containerd /var/lib/containerd

        # Add to fstab for persistence
        grep -q "lv_containerd" /etc/fstab || \
          echo "/dev/vg_data/lv_containerd /var/lib/containerd xfs defaults,nofail 0 2" >> /etc/fstab

        echo "Containerd data migration completed"
        df -h /var/lib/containerd

        # Start containerd with migrated data
        systemctl start containerd
    privateNetworking: true
    subnets:
      - ${PRIVATE_SUBNET_A}
      - ${PRIVATE_SUBNET_B}
      - ${PRIVATE_SUBNET_C}
    labels:
      app: "eks-utils"
      arch: "amd64"
      node-group-type: "system"
    tags:
      k8s.io/cluster-autoscaler/enabled: "true"
      k8s.io/cluster-autoscaler/${CLUSTER_NAME}: "owned"

addons:
  - name: vpc-cni
    version: latest
  - name: coredns
    version: latest
    configurationValues: |
      nodeSelector:
        app: eks-utils
  - name: kube-proxy
    version: latest
  - name: eks-pod-identity-agent
    version: latest
  - name: aws-ebs-csi-driver
    version: latest

cloudWatch:
  clusterLogging:
    logRetentionInDays: 30
    enableTypes:
      - "api"
      - "audit"
      - "authenticator"
      - "controllerManager"
      - "scheduler"
