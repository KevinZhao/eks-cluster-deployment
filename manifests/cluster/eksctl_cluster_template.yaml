apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: ${CLUSTER_NAME}
  region: ${AWS_DEFAULT_REGION}
  version: "${K8S_VERSION}"
  tags:
    cluster-autoscaler: enabled

# Kubernetes 网络配置
kubernetesNetworkConfig:
  serviceIPv4CIDR: "${SERVICE_IPV4_CIDR}"

# 使用已经存在的vpc
vpc:
  id: "${VPC_ID}"
  subnets:
    private:
      ${AZ_2A}:
        id: "${PRIVATE_SUBNET_2A}"
      ${AZ_2B}:
        id: "${PRIVATE_SUBNET_2B}"
      ${AZ_2C}:
        id: "${PRIVATE_SUBNET_2C}"
    public:
      ${AZ_2A}:
        id: "${PUBLIC_SUBNET_2A}"
      ${AZ_2B}:
        id: "${PUBLIC_SUBNET_2B}"
      ${AZ_2C}:
        id: "${PUBLIC_SUBNET_2C}"
  clusterEndpoints:
    privateAccess: true
    publicAccess: false

accessConfig:
  authenticationMode: API_AND_CONFIG_MAP

# 无须修改
iam:
  withOIDC: true
  serviceAccounts:
    # Cluster Autoscaler service account
    - metadata:
        name: cluster-autoscaler
        namespace: kube-system
      wellKnownPolicies:
        autoScaler: true
      roleName: ${CLUSTER_NAME}-cluster-autoscaler-role
    # EBS CSI driver service account
    - metadata:
        name: ebs-csi-controller-sa
        namespace: kube-system
      wellKnownPolicies:
        ebsCSIController: true
      roleName: ${CLUSTER_NAME}-ebs-csi-driver-role
    # EFS CSI driver service account
    - metadata:
        name: efs-csi-controller-sa
        namespace: kube-system
      wellKnownPolicies:
        efsCSIController: true
      roleName: ${CLUSTER_NAME}-efs-csi-driver-role
    # S3 CSI driver service account
    # WARNING: AmazonS3FullAccess grants s3:* on all buckets (security risk)
    # RECOMMENDED: Create custom policy with least privilege (see scripts/5_create_s3_csi_policy.sh)
    # Uncomment below if S3 mounting is needed with proper custom policy:
    # - metadata:
    #     name: s3-csi-driver-sa
    #     namespace: kube-system
    #   attachPolicyARNs:
    #     - arn:${AWS_PARTITION}:iam::${ACCOUNT_ID}:policy/${CLUSTER_NAME}-S3CSIDriverPolicy
    #   roleName: ${CLUSTER_NAME}-s3-csi-driver-role

# 节点组配置
# 系统节点组，主要运行aws-load-balancer-controller coredns cluster-autoscaler等组件
managedNodeGroups:
  - name: eks-utils
    instanceType: m7i.large
    amiFamily: AmazonLinux2023
    desiredCapacity: 3
    minSize: 3
    maxSize: 6
    volumeSize: 30
    volumeType: gp3
    privateNetworking: true
    subnets:
      - ${PRIVATE_SUBNET_2A}
      - ${PRIVATE_SUBNET_2B}
      - ${PRIVATE_SUBNET_2C}
    labels:
      app: "eks-utils"
      arch: "amd64"
    tags:
      k8s.io/cluster-autoscaler/enabled: "true"
      k8s.io/cluster-autoscaler/${CLUSTER_NAME}: "owned"

  - name: app
    instanceType: c8g.large
    amiFamily: AmazonLinux2023
    desiredCapacity: 3
    minSize: 3
    maxSize: 12
    volumeSize: 30
    volumeType: gp3
    privateNetworking: true
    subnets:
      - ${PRIVATE_SUBNET_2A}
      - ${PRIVATE_SUBNET_2B}
      - ${PRIVATE_SUBNET_2C}
    labels:
      app: application
      arch: "arm64"
      workload: "user-apps"
    taints:
      - key: "workload"
        value: "user-apps"
        effect: "NoSchedule"
    tags:
      k8s.io/cluster-autoscaler/enabled: "true"
      k8s.io/cluster-autoscaler/${CLUSTER_NAME}: "owned"

addons:
  - name: vpc-cni
    version: latest
  - name: coredns
    version: latest
    configurationValues: |
      nodeSelector:
        app: eks-utils
  - name: kube-proxy
    version: latest
  - name: eks-pod-identity-agent
    version: latest
  - name: aws-ebs-csi-driver
    version: latest
    serviceAccountRoleArn: arn:${AWS_PARTITION}:iam::${ACCOUNT_ID}:role/${CLUSTER_NAME}-ebs-csi-driver-role

cloudWatch:
  clusterLogging:
    logRetentionInDays: 30
    enableTypes:
      - "api"
      - "audit"
      - "authenticator"
      - "controllerManager"
      - "scheduler"
