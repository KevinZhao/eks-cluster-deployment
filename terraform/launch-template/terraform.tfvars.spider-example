# ============================================
# Spider Example Configuration
# ============================================
# 这是一个完整的示例配置，展示如何:
# 1. 使用自定义 SSH Key (spider.pem)
# 2. 添加 1000GB 数据盘
# 3. 自定义 User Data 脚本
# ============================================

# AWS Configuration
aws_region   = "ap-southeast-1"
cluster_name = "eks-demo-1"
k8s_version  = "1.34"
vpc_id       = "vpc-02152cca66eb91fe7"

# ============================================
# Instance Configuration
# ============================================
instance_type = "c8g.large"  # ARM64 Graviton3, 2 vCPU, 4GB RAM

# SSH Key - 使用你的 spider key
key_name = "spider"  # AWS 中的 key pair 名称（不包含 .pem 后缀）

# ============================================
# Root Volume Configuration (系统盘)
# ============================================
root_volume_size       = 30      # 30GB 系统盘
root_volume_type       = "gp3"   # gp3 性能更好且更便宜
root_volume_iops       = 3000    # 基线 3000 IOPS
root_volume_throughput = 125     # 基线 125 MB/s

# ============================================
# Data Volume Configuration (数据盘)
# ============================================
data_volume_size       = 1000    # 1000GB 数据盘
data_volume_type       = "gp3"   # 推荐使用 gp3
data_volume_iops       = 5000    # 5000 IOPS (gp3 最大 16000)
data_volume_throughput = 250     # 250 MB/s (gp3 最大 1000)

# ============================================
# Monitoring Configuration
# ============================================
enable_monitoring = true  # 启用详细监控（额外费用）

# ============================================
# Custom User Data Script
# ============================================
custom_userdata = <<-EOT
# ============================================
# Spider Project - Node Initialization Script
# ============================================

# 日志文件
INIT_LOG="/var/log/spider-node-init.log"
exec > >(tee -a $INIT_LOG)
exec 2>&1

echo "=================================="
echo "Spider Node Initialization Started"
echo "Time: $(date)"
echo "Hostname: $(hostname)"
echo "=================================="

# ============================================
# 1. 挂载 1000GB 数据盘
# ============================================
echo "[$(date)] Step 1: Mounting data volume..."

if [ -e /dev/xvdb ]; then
    echo "Found data volume /dev/xvdb"

    # 检查是否已经有文件系统
    if ! blkid /dev/xvdb; then
        echo "Creating XFS filesystem on /dev/xvdb..."
        mkfs -t xfs /dev/xvdb
    else
        echo "Filesystem already exists on /dev/xvdb"
    fi

    # 创建挂载点
    mkdir -p /data

    # 挂载
    mount /dev/xvdb /data

    # 添加到 fstab（使用 UUID 更安全）
    UUID=$(blkid -s UUID -o value /dev/xvdb)
    if ! grep -q "$UUID" /etc/fstab; then
        echo "UUID=$UUID /data xfs defaults,nofail 0 2" >> /etc/fstab
        echo "Added /data to fstab with UUID=$UUID"
    fi

    # 验证挂载
    df -h /data
    echo "Data volume mounted successfully at /data"
else
    echo "WARNING: Data volume /dev/xvdb not found!"
fi

# ============================================
# 2. 创建数据目录结构
# ============================================
echo "[$(date)] Step 2: Creating directory structure..."

# Spider 项目相关目录
mkdir -p /data/spider/{logs,cache,downloads,config,backups}
mkdir -p /data/app/{logs,temp,uploads}
mkdir -p /data/mysql/data
mkdir -p /data/redis/data
mkdir -p /data/mongodb/data

# 设置权限
chmod -R 755 /data/spider
chmod -R 755 /data/app

echo "Directory structure created:"
tree -L 2 /data || ls -la /data

# ============================================
# 3. 安装额外的软件包
# ============================================
echo "[$(date)] Step 3: Installing additional packages..."

# 更新 yum 仓库
yum update -y

# 开发工具
yum groupinstall -y "Development Tools"

# 系统监控和调试工具
yum install -y \
    htop \
    iotop \
    sysstat \
    net-tools \
    tcpdump \
    telnet \
    nc \
    lsof \
    strace \
    tree \
    vim \
    wget \
    curl \
    jq \
    git

# Python 3 和相关工具（用于爬虫）
yum install -y \
    python3 \
    python3-pip \
    python3-devel

# 升级 pip
pip3 install --upgrade pip

# 安装常用 Python 包
pip3 install \
    requests \
    beautifulsoup4 \
    selenium \
    scrapy \
    redis \
    pymongo \
    pymysql

# Docker Compose（如果需要）
curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose

echo "Package installation completed"

# ============================================
# 4. 系统优化配置
# ============================================
echo "[$(date)] Step 4: Applying system optimizations..."

# 增加文件描述符限制
cat >> /etc/security/limits.conf <<EOF
# Spider project limits
* soft nofile 65536
* hard nofile 65536
* soft nproc 65536
* hard nproc 65536
root soft nofile 65536
root hard nofile 65536
root soft nproc 65536
root hard nproc 65536
EOF

# 内核参数优化
cat >> /etc/sysctl.conf <<EOF

# Spider project kernel optimizations
# 网络优化
net.core.somaxconn = 4096
net.core.netdev_max_backlog = 8192
net.ipv4.tcp_max_syn_backlog = 8192
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_tw_reuse = 1
net.ipv4.ip_local_port_range = 10000 65535

# 内存优化
vm.swappiness = 10
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5

# 文件系统优化
fs.file-max = 2097152
fs.inotify.max_user_watches = 524288
EOF

# 应用内核参数
sysctl -p

echo "System optimizations applied"

# ============================================
# 5. 配置时区和 NTP
# ============================================
echo "[$(date)] Step 5: Configuring timezone and NTP..."

# 设置时区（新加坡）
timedatectl set-timezone Asia/Singapore

# 启用 chrony（Amazon Linux 2023 默认）
systemctl enable chronyd
systemctl start chronyd

echo "Timezone: $(timedatectl | grep 'Time zone')"

# ============================================
# 6. 创建 Spider 配置文件
# ============================================
echo "[$(date)] Step 6: Creating Spider configuration..."

cat > /data/spider/config/spider.conf <<EOF
# Spider Project Configuration
# Generated at: $(date)

[spider]
data_dir = /data/spider/downloads
log_dir = /data/spider/logs
cache_dir = /data/spider/cache
backup_dir = /data/spider/backups

[database]
mysql_host = localhost
mysql_port = 3306
redis_host = localhost
redis_port = 6379
mongodb_host = localhost
mongodb_port = 27017

[limits]
max_concurrent_requests = 100
request_timeout = 30
retry_times = 3

[logging]
log_level = INFO
log_rotation = daily
log_retention_days = 30
EOF

chmod 644 /data/spider/config/spider.conf
echo "Spider configuration created at /data/spider/config/spider.conf"

# ============================================
# 7. 创建启动脚本
# ============================================
echo "[$(date)] Step 7: Creating startup scripts..."

cat > /data/spider/start.sh <<'EOF'
#!/bin/bash
# Spider Project Startup Script

echo "Starting Spider services..."
cd /data/spider

# 检查数据目录
if [ ! -d "/data/spider/downloads" ]; then
    echo "Error: Data directories not found!"
    exit 1
fi

# 启动你的爬虫服务
# python3 /data/spider/spider_master.py &

echo "Spider services started"
EOF

chmod +x /data/spider/start.sh

# ============================================
# 8. 设置 Cron 任务
# ============================================
echo "[$(date)] Step 8: Setting up cron jobs..."

# 创建日志清理任务
cat > /etc/cron.daily/spider-cleanup <<'EOF'
#!/bin/bash
# 清理 30 天前的日志
find /data/spider/logs -name "*.log" -mtime +30 -delete
find /data/app/logs -name "*.log" -mtime +30 -delete
echo "$(date): Log cleanup completed" >> /var/log/spider-cleanup.log
EOF

chmod +x /etc/cron.daily/spider-cleanup

echo "Cron jobs configured"

# ============================================
# 9. 创建监控脚本
# ============================================
echo "[$(date)] Step 9: Creating monitoring script..."

cat > /usr/local/bin/spider-monitor.sh <<'EOF'
#!/bin/bash
# Spider 节点监控脚本

echo "=================================="
echo "Spider Node Health Check"
echo "Time: $(date)"
echo "=================================="

# 磁盘使用率
echo "Disk Usage:"
df -h /data

# 内存使用
echo -e "\nMemory Usage:"
free -h

# 系统负载
echo -e "\nSystem Load:"
uptime

# 网络连接数
echo -e "\nNetwork Connections:"
ss -s

# Top 10 进程（按内存）
echo -e "\nTop 10 Processes (by memory):"
ps aux --sort=-%mem | head -11
EOF

chmod +x /usr/local/bin/spider-monitor.sh

# ============================================
# 10. 创建节点信息文件
# ============================================
echo "[$(date)] Step 10: Creating node info file..."

cat > /data/node-info.txt <<EOF
================================
Spider EKS Node Information
================================
Initialized: $(date)
Hostname: $(hostname)
Instance ID: $(ec2-metadata --instance-id | cut -d ' ' -f 2)
Instance Type: $(ec2-metadata --instance-type | cut -d ' ' -f 2)
Availability Zone: $(ec2-metadata --availability-zone | cut -d ' ' -f 2)
Private IP: $(ec2-metadata --local-ipv4 | cut -d ' ' -f 2)
Public IP: $(ec2-metadata --public-ipv4 | cut -d ' ' -f 2)

Disk Configuration:
$(lsblk)

Mount Points:
$(df -h)

Installed Packages:
- Python: $(python3 --version)
- Docker: $(docker --version)
- Docker Compose: $(docker-compose --version)
- Git: $(git --version)

================================
EOF

cat /data/node-info.txt

# ============================================
# 11. 设置系统别名
# ============================================
echo "[$(date)] Step 11: Setting up shell aliases..."

cat >> /root/.bashrc <<'EOF'

# Spider Project Aliases
alias spider-logs='tail -f /data/spider/logs/*.log'
alias spider-status='systemctl status kubelet docker'
alias spider-monitor='/usr/local/bin/spider-monitor.sh'
alias spider-start='/data/spider/start.sh'
alias goto-spider='cd /data/spider'
alias goto-data='cd /data'
alias disk-usage='df -h /data'
EOF

# ============================================
# 12. 发送初始化完成通知（可选）
# ============================================
echo "[$(date)] Step 12: Sending initialization notification..."

# 如果配置了 SNS，可以发送通知
# aws sns publish --topic-arn arn:aws:sns:region:account:topic --message "Node $(hostname) initialized"

# ============================================
# 完成
# ============================================
echo "=================================="
echo "Spider Node Initialization Completed"
echo "Time: $(date)"
echo "=================================="
echo ""
echo "Quick commands:"
echo "  - Check node info: cat /data/node-info.txt"
echo "  - Monitor node: spider-monitor"
echo "  - View logs: spider-logs"
echo "  - Go to spider dir: goto-spider"
echo ""
echo "Log file: $INIT_LOG"
echo "=================================="

# 标记初始化完成
touch /data/.spider-node-initialized
date > /data/.spider-node-initialized
EOT

# ============================================
# Tags Configuration
# ============================================
common_tags = {
  Environment = "production"
  ManagedBy   = "terraform"
  Project     = "spider-crawler"
  Owner       = "spider-team"
  CostCenter  = "engineering"
}
