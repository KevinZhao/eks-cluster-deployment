# EKS é›†ç¾¤è‡ªåŠ¨åŒ–éƒ¨ç½²å®Œæ•´æŒ‡å—

ç”Ÿäº§çº§ AWS EKS é›†ç¾¤è‡ªåŠ¨åŒ–éƒ¨ç½²æ–¹æ¡ˆï¼Œæ”¯æŒæ ‡å‡†éƒ¨ç½²å’Œè‡ªå®šä¹‰ Launch Template éƒ¨ç½²ã€‚

[![Kubernetes](https://img.shields.io/badge/Kubernetes-1.34-326CE5?logo=kubernetes)](https://kubernetes.io/)
[![AWS](https://img.shields.io/badge/AWS-EKS-FF9900?logo=amazon-aws)](https://aws.amazon.com/eks/)

---

## ğŸ“‹ ç›®å½•

- [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ¶æ„è¯´æ˜](#æ¶æ„è¯´æ˜)
- [éƒ¨ç½²æ–¹å¼é€‰æ‹©](#éƒ¨ç½²æ–¹å¼é€‰æ‹©)
- [å‰ç½®è¦æ±‚](#å‰ç½®è¦æ±‚)
- [æ ‡å‡†éƒ¨ç½²](#æ ‡å‡†éƒ¨ç½²)
- [Launch Template éƒ¨ç½²](#launch-template-éƒ¨ç½²)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [æˆæœ¬ä¼˜åŒ–](#æˆæœ¬ä¼˜åŒ–)
- [éªŒè¯å’Œæµ‹è¯•](#éªŒè¯å’Œæµ‹è¯•)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
- [æ¸…ç†èµ„æº](#æ¸…ç†èµ„æº)

---

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½
- âœ… **è‡ªåŠ¨åŒ–éƒ¨ç½²** - ä¸€é”®éƒ¨ç½²å®Œæ•´ EKS é›†ç¾¤
- âœ… **å¤š AZ é«˜å¯ç”¨** - è·¨ 3 ä¸ªå¯ç”¨åŒºéƒ¨ç½²
- âœ… **æ··åˆæ¶æ„** - ç³»ç»ŸèŠ‚ç‚¹ Intelï¼Œåº”ç”¨èŠ‚ç‚¹ Gravitonï¼Œå…¼é¡¾å…¼å®¹æ€§å’Œæˆæœ¬
- âœ… **å·¥ä½œè´Ÿè½½éš”ç¦»** - ç³»ç»Ÿç»„ä»¶å’Œåº”ç”¨å®Œå…¨éš”ç¦»
- âœ… **è‡ªåŠ¨æ‰©ç¼©å®¹** - Cluster Autoscaler è‡ªåŠ¨ç®¡ç†èŠ‚ç‚¹
- âœ… **å­˜å‚¨æ”¯æŒ** - EBS/EFS/S3 CSI Driver
- âœ… **è´Ÿè½½å‡è¡¡** - AWS Load Balancer Controller
- âœ… **è‡ªå®šä¹‰èŠ‚ç‚¹** - æ”¯æŒ Launch Template è‡ªå®šä¹‰é…ç½®ï¼ˆSSH Keyã€æ•°æ®ç›˜ã€é¢„è£…è½¯ä»¶ï¼‰

### æ”¯æŒçš„å­˜å‚¨ç±»å‹
- **EBS** (gp3) - å—å­˜å‚¨ï¼Œé€‚åˆæ•°æ®åº“
- **EFS** - å…±äº«æ–‡ä»¶ç³»ç»Ÿï¼Œé€‚åˆå¤š Pod è®¿é—®
- **S3** (Mountpoint) - å¯¹è±¡å­˜å‚¨ï¼Œé€‚åˆå¤§æ•°æ®

### å·²é›†æˆç»„ä»¶
| ç»„ä»¶ | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|
| Kubernetes | 1.34 | å®¹å™¨ç¼–æ’ |
| VPC CNI | v1.18.5 | Pod ç½‘ç»œ |
| CoreDNS | v1.11.3 | DNS è§£æ |
| Kube-proxy | v1.31.2 | ç½‘ç»œä»£ç† |
| Pod Identity Agent | v1.3.4 | IAM è®¤è¯ |
| EBS CSI Driver | v1.37.0 | å—å­˜å‚¨ |
| Cluster Autoscaler | v1.34.2 | è‡ªåŠ¨æ‰©ç¼©å®¹ |
| AWS LB Controller | v2.11.0 | è´Ÿè½½å‡è¡¡ |

---

## âš¡ å¿«é€Ÿå¼€å§‹

### æœ€ç®€éƒ¨ç½²ï¼ˆ5 åˆ†é’Ÿé…ç½® + 20 åˆ†é’Ÿç­‰å¾…ï¼‰

```bash
# 1. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
nano .env  # å¡«å†™ VPC_IDã€å­ç½‘ ID ç­‰

# 2. éƒ¨ç½²é›†ç¾¤
chmod +x scripts/*.sh
./scripts/4_install_eks_cluster.sh
```

**éƒ¨ç½²æ—¶é—´:** çº¦ 20-25 åˆ†é’Ÿ

---

## ğŸ—ï¸ æ¶æ„è¯´æ˜

### é›†ç¾¤æ¶æ„

```
EKS Cluster (Kubernetes 1.34)
â”œâ”€â”€ Control Plane (AWS æ‰˜ç®¡)
â”‚   â””â”€â”€ API Server (å†…ç½‘è®¿é—®)
â”‚
â”œâ”€â”€ eks-utils èŠ‚ç‚¹ç»„ (3x m7i.large, Intel)
â”‚   â”œâ”€â”€ æ—  Taint
â”‚   â””â”€â”€ è¿è¡Œ: CoreDNS, Cluster Autoscaler, LB Controller, CSI Controllers
â”‚
â””â”€â”€ app èŠ‚ç‚¹ç»„ (3x c8g.large, Graviton ARM64)
    â”œâ”€â”€ Taint: workload=user-apps:NoSchedule
    â””â”€â”€ è¿è¡Œ: ç”¨æˆ·åº”ç”¨ï¼ˆéœ€è¦ tolerationï¼‰
```

### ç½‘ç»œæ¶æ„

```
VPC (10.0.0.0/16)
â”œâ”€â”€ 3ä¸ªå¯ç”¨åŒº
â”‚   â”œâ”€â”€ Public Subnet â†’ IGW
â”‚   â”‚   â””â”€â”€ NAT Gateway
â”‚   â””â”€â”€ Private Subnet â†’ NAT GW
â”‚       â””â”€â”€ EKS èŠ‚ç‚¹
```

---

## ğŸ¯ éƒ¨ç½²æ–¹å¼é€‰æ‹©

### æ–¹å¼ 1: æ ‡å‡†éƒ¨ç½² â­ æ¨èæ–°æ‰‹

**ç‰¹ç‚¹:**
- âœ… é…ç½®ç®€å•ï¼Œåªéœ€ .env æ–‡ä»¶
- âœ… å¿«é€Ÿéƒ¨ç½²ï¼Œçº¦ 20 åˆ†é’Ÿ
- âŒ æ— æ³•è‡ªå®šä¹‰ SSH Key
- âŒ æ— æ³•æ·»åŠ æ•°æ®ç›˜
- âŒ æ— æ³•è‡ªå®šä¹‰ User Data

**é€‚ç”¨:** æµ‹è¯•ç¯å¢ƒã€å­¦ä¹ ã€æ¼”ç¤º

**å‘½ä»¤:**
```bash
./scripts/4_install_eks_cluster.sh
```

### æ–¹å¼ 2: Launch Template éƒ¨ç½² â­ æ¨èç”Ÿäº§

**ç‰¹ç‚¹:**
- âœ… å®Œå…¨è‡ªå®šä¹‰èŠ‚ç‚¹é…ç½®
- âœ… æ”¯æŒ SSH Keyï¼ˆå¦‚ spider.pemï¼‰
- âœ… æ”¯æŒé¢å¤–æ•°æ®ç›˜ï¼ˆå¦‚ 1000GBï¼‰
- âœ… æ”¯æŒè‡ªå®šä¹‰ User Dataï¼ˆé¢„è£…è½¯ä»¶ã€ç³»ç»Ÿä¼˜åŒ–ï¼‰
- âœ… Terraform ç®¡ç†ï¼ŒçŠ¶æ€å¯è¿½è¸ª

**é€‚ç”¨:** ç”Ÿäº§ç¯å¢ƒã€éœ€è¦ SSHã€éœ€è¦æ•°æ®ç›˜ã€éœ€è¦é¢„è£…è½¯ä»¶

**å‘½ä»¤:**
```bash
./scripts/6_install_eks_with_custom_nodegroup.sh
```

### å¯¹æ¯”è¡¨æ ¼

| ç‰¹æ€§ | æ ‡å‡†éƒ¨ç½² | Launch Template |
|------|---------|----------------|
| å¤æ‚åº¦ | â­ ç®€å• | â­â­â­ ä¸­ç­‰ |
| SSH Key | âŒ | âœ… |
| æ•°æ®ç›˜ | âŒ | âœ… |
| é¢„è£…è½¯ä»¶ | âŒ | âœ… |
| ç³»ç»Ÿä¼˜åŒ– | âŒ | âœ… |
| éƒ¨ç½²æ—¶é—´ | 20åˆ†é’Ÿ | 25-30åˆ†é’Ÿ |

---

## ğŸ“¦ å‰ç½®è¦æ±‚

### 1. AWS ç½‘ç»œç¯å¢ƒ

**å¿…é¡»é¢„å…ˆåˆ›å»º:**
- 1 ä¸ª VPC
- 3 ä¸ªå…¬æœ‰å­ç½‘ï¼ˆæ¯ä¸ª AZï¼‰
- 3 ä¸ªç§æœ‰å­ç½‘ï¼ˆæ¯ä¸ª AZï¼‰
- NAT Gatewayï¼ˆè‡³å°‘ 1 ä¸ªï¼Œå»ºè®® 3 ä¸ªï¼‰
- Internet Gateway

**å¿«é€Ÿåˆ›å»º VPC:**
```bash
cd terraform/vpc
terraform init
terraform apply

# è·å–è¾“å‡ºç”¨äº .env
terraform output env_file_format
```

### 2. å·¥å…·è¦æ±‚

| å·¥å…· | æœ€å°ç‰ˆæœ¬ | æ£€æŸ¥å‘½ä»¤ |
|------|---------|---------|
| AWS CLI | v2.x | `aws --version` |
| eksctl | v0.150+ | `eksctl version` |
| kubectl | v1.31+ | `kubectl version --client` |
| helm | v3.x | `helm version` |
| envsubst | - | `envsubst --version` |
| terraform* | v1.0+ | `terraform version` |

*ä»… Launch Template éƒ¨ç½²éœ€è¦

**ä¸€é”®å®‰è£…ï¼ˆAmazon Linux 2023ï¼‰:**
```bash
sudo yum install -y aws-cli kubectl gettext

curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin

curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# terraformï¼ˆå¯é€‰ï¼‰
wget https://releases.hashicorp.com/terraform/1.7.0/terraform_1.7.0_linux_amd64.zip
unzip terraform_1.7.0_linux_amd64.zip
sudo mv terraform /usr/local/bin/
```

### 3. AWS æƒé™

éœ€è¦: EKSã€EC2ã€IAMã€CloudWatch Logsã€VPC æƒé™

---

## ğŸ”§ æ ‡å‡†éƒ¨ç½²

### Step 1: é…ç½®ç¯å¢ƒå˜é‡

```bash
cp .env.example .env
nano .env
```

**å¿…å¡«:**
```bash
CLUSTER_NAME=eks-demo-1
VPC_ID=vpc-xxxxxxxxxxxxxxxxx
PRIVATE_SUBNET_2A=subnet-xxxxxxxxxxxxxxxxx
PRIVATE_SUBNET_2B=subnet-xxxxxxxxxxxxxxxxx
PRIVATE_SUBNET_2C=subnet-xxxxxxxxxxxxxxxxx
PUBLIC_SUBNET_2A=subnet-xxxxxxxxxxxxxxxxx
PUBLIC_SUBNET_2B=subnet-xxxxxxxxxxxxxxxxx
PUBLIC_SUBNET_2C=subnet-xxxxxxxxxxxxxxxxx
AWS_REGION=ap-southeast-1
AWS_DEFAULT_REGION=ap-southeast-1
```

### Step 2: æ‰§è¡Œéƒ¨ç½²

```bash
chmod +x scripts/*.sh
./scripts/4_install_eks_cluster.sh
```

**è‡ªåŠ¨æ‰§è¡Œ:**
1. åˆ›å»º EKS é›†ç¾¤ï¼ˆ15-20åˆ†é’Ÿï¼‰
2. éƒ¨ç½² Cluster Autoscaler
3. å®‰è£… AWS Load Balancer Controller
4. è¿ç§»åˆ° Pod Identity

### Step 3: éªŒè¯

```bash
# æ£€æŸ¥èŠ‚ç‚¹ï¼ˆåº”è¯¥æœ‰ 6 ä¸ªï¼‰
kubectl get nodes -o wide

# æ£€æŸ¥ç³»ç»Ÿç»„ä»¶
kubectl get pods -n kube-system

# æ£€æŸ¥ Cluster Autoscaler
kubectl logs -n kube-system -l app=cluster-autoscaler --tail=20
```

---

## ğŸ¨ Launch Template éƒ¨ç½²

### ä½¿ç”¨åœºæ™¯ï¼šçˆ¬è™«é¡¹ç›®ç¤ºä¾‹

**éœ€æ±‚:**
- SSH Key: spider.pem
- æ•°æ®ç›˜: 1000GB
- é¢„è£…: Pythonã€çˆ¬è™«åº“ã€ç›‘æ§å·¥å…·
- ä¼˜åŒ–: æ–‡ä»¶æè¿°ç¬¦ã€TCP å‚æ•°

### Step 1: åˆ›å»º SSH Key

```bash
# åˆ›å»ºæ–° key
aws ec2 create-key-pair \
  --key-name spider \
  --region ap-southeast-1 \
  --query 'KeyMaterial' \
  --output text > spider.pem
chmod 400 spider.pem

# éªŒè¯
aws ec2 describe-key-pairs --key-names spider --region ap-southeast-1
```

### Step 2: é…ç½® Launch Template

```bash
cd terraform/launch-template

# ä½¿ç”¨ç¤ºä¾‹é…ç½®
cp terraform.tfvars.spider-example terraform.tfvars

# æŸ¥çœ‹é…ç½®
cat terraform.tfvars
```

**é…ç½®å†…å®¹ç¤ºä¾‹:**
```hcl
key_name = "spider"
instance_type = "c8g.large"

# ç³»ç»Ÿç›˜
root_volume_size = 30
root_volume_type = "gp3"

# æ•°æ®ç›˜ 1000GB
data_volume_size = 1000
data_volume_type = "gp3"
data_volume_iops = 5000
data_volume_throughput = 250

# è‡ªå®šä¹‰ User Data
custom_userdata = <<-EOT
  # æŒ‚è½½ 1000GB æ•°æ®ç›˜åˆ° /data
  if [ -e /dev/xvdb ]; then
    mkfs -t xfs /dev/xvdb
    mkdir -p /data
    mount /dev/xvdb /data
    echo '/dev/xvdb /data xfs defaults,nofail 0 2' >> /etc/fstab
  fi
  
  # å®‰è£… Python + çˆ¬è™«åº“
  yum install -y python3 python3-pip htop
  pip3 install requests beautifulsoup4 scrapy selenium
  
  # ç³»ç»Ÿä¼˜åŒ–
  echo "* soft nofile 65536" >> /etc/security/limits.conf
  echo "* hard nofile 65536" >> /etc/security/limits.conf
EOT
```

### Step 3: ä¸€é”®éƒ¨ç½²

```bash
cd ../..
./scripts/6_install_eks_with_custom_nodegroup.sh
```

**æ‰§è¡Œæµç¨‹:**
1. æ£€æŸ¥ SSH Key
2. Terraform åˆ›å»º Launch Templateï¼ˆ1-2åˆ†é’Ÿï¼‰
3. åˆ›å»º EKS åŸºç¡€é›†ç¾¤ï¼ˆ15-20åˆ†é’Ÿï¼‰
4. åˆ›å»º app èŠ‚ç‚¹ç»„ï¼ˆ5-10åˆ†é’Ÿï¼‰
5. éƒ¨ç½² Autoscaler å’Œ LB Controller

### Step 4: éªŒè¯è‡ªå®šä¹‰é…ç½®

```bash
# è·å–å®ä¾‹ ID
INSTANCE_ID=$(aws ec2 describe-instances \
  --filters "Name=tag:Name,Values=*app-node*" \
            "Name=instance-state-name,Values=running" \
  --query 'Reservations[0].Instances[0].InstanceId' \
  --output text --region ap-southeast-1)

# ä½¿ç”¨ SSM è¿æ¥
aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1

# åœ¨èŠ‚ç‚¹ä¸ŠéªŒè¯
sudo cat /var/log/spider-node-init.log  # åˆå§‹åŒ–æ—¥å¿—
df -h /data                              # éªŒè¯æ•°æ®ç›˜
tree -L 2 /data                          # æŸ¥çœ‹ç›®å½•
python3 --version                        # éªŒè¯ Python
pip3 list | grep scrapy                  # éªŒè¯åº“
```

### Step 5: ä½¿ç”¨ SSHï¼ˆå¯é€‰ï¼‰

```bash
# ä» VPC å†…éƒ¨
NODE_IP=$(kubectl get nodes -l workload=user-apps \
  -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}')

ssh -i spider.pem ec2-user@$NODE_IP
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### .env é…ç½®

**å¿…éœ€:**
```bash
CLUSTER_NAME=eks-demo-1
VPC_ID=vpc-xxx
PRIVATE_SUBNET_2A=subnet-xxx
PRIVATE_SUBNET_2B=subnet-xxx
PRIVATE_SUBNET_2C=subnet-xxx
PUBLIC_SUBNET_2A=subnet-xxx
PUBLIC_SUBNET_2B=subnet-xxx
PUBLIC_SUBNET_2C=subnet-xxx
AWS_REGION=ap-southeast-1
AWS_DEFAULT_REGION=ap-southeast-1
```

**å¯é€‰:**
```bash
K8S_VERSION=1.34
SERVICE_IPV4_CIDR=172.20.0.0/16
AZ_2A=ap-southeast-1a
AZ_2B=ap-southeast-1b
AZ_2C=ap-southeast-1c
```

### Launch Template é…ç½®

**å®Œæ•´ç¤ºä¾‹ï¼ˆterraform.tfvarsï¼‰:**
```hcl
aws_region   = "ap-southeast-1"
cluster_name = "eks-demo-1"
vpc_id       = "vpc-xxx"

# SSH Key
key_name = "spider"

# å®ä¾‹
instance_type = "c8g.large"

# æ ¹å·
root_volume_size = 30
root_volume_type = "gp3"

# æ•°æ®ç›˜
data_volume_size = 1000
data_volume_type = "gp3"
data_volume_iops = 5000
data_volume_throughput = 250

# User Data
custom_userdata = <<-EOT
# ä½ çš„è‡ªå®šä¹‰è„šæœ¬
EOT
```

---

## ğŸ’° æˆæœ¬ä¼˜åŒ–

### æ ‡å‡†éƒ¨ç½²æˆæœ¬ï¼ˆæ–°åŠ å¡ï¼‰

| é¡¹ç›® | é…ç½® | æœˆåº¦ |
|------|------|------|
| EKS Control Plane | - | $72 |
| eks-utils | 3x m7i.large | $263 |
| app | 3x c8g.large | $180 |
| EBS | 6x 30GB gp3 | $18 |
| Logs | 30å¤© | $30 |
| NAT GW | 3ä¸ª | $96 |
| **æ€»è®¡** | | **$659** |

### Launch Templateï¼ˆå«1000GBæ•°æ®ç›˜ï¼‰

| é¡¹ç›® | æœˆåº¦ |
|------|------|
| åŸºç¡€ | $659 |
| **æ•°æ®ç›˜** | **+$300** |
| **æ€»è®¡** | **$959** |

### ä¼˜åŒ–å»ºè®®

**1. ä½¿ç”¨ Spot å®ä¾‹ï¼ˆèŠ‚çœ ~70%ï¼‰**
```yaml
spot: true
instanceTypes: ["c8g.large", "c7g.large"]
```
èŠ‚çœ: ~$126/æœˆ

**2. å• NAT Gateway**
```hcl
single_nat_gateway = true
```
èŠ‚çœ: $64/æœˆ

**3. å‡å°‘æ•°æ®ç›˜**
```hcl
data_volume_size = 500
```
èŠ‚çœ: $150/æœˆ

**ä¼˜åŒ–å:** $469-619/æœˆï¼ˆèŠ‚çœ 29-51%ï¼‰

---

## âœ… éªŒè¯å’Œæµ‹è¯•

### 1. éªŒè¯é›†ç¾¤

```bash
# èŠ‚ç‚¹
kubectl get nodes -o wide

# æ ‡ç­¾
kubectl get nodes --show-labels

# Taints
kubectl get nodes -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints

# Pod
kubectl get pods -A -o wide
```

### 2. æµ‹è¯• Autoscaler

```bash
# éƒ¨ç½²æµ‹è¯•
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: test
  template:
    metadata:
      labels:
        app: test
    spec:
      tolerations:
      - key: "workload"
        operator: "Equal"
        value: "user-apps"
        effect: "NoSchedule"
      nodeSelector:
        workload: user-apps
      containers:
      - name: nginx
        image: nginx:alpine
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
EOF

# æ‰©å®¹è§¦å‘è‡ªåŠ¨æ‰©å®¹
kubectl scale deployment test --replicas=10
watch kubectl get nodes

# ç¼©å®¹
kubectl scale deployment test --replicas=0

# æ¸…ç†
kubectl delete deployment test
```

### 3. æµ‹è¯• Load Balancer

```bash
# éƒ¨ç½² 2048 æ¸¸æˆ
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.13.0/docs/examples/2048/2048_full.yaml

# ç­‰å¾… ALBï¼ˆ3-5 åˆ†é’Ÿï¼‰
kubectl get ingress -n game-2048 -w

# è®¿é—®
ALB_URL=$(kubectl get ingress -n game-2048 -o jsonpath='{.items[0].status.loadBalancer.ingress[0].hostname}')
echo "http://$ALB_URL"

# æ¸…ç†
kubectl delete namespace game-2048
```

### 4. æµ‹è¯• EBS

```bash
# åˆ›å»º PVC
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: test-pvc
spec:
  accessModes: [ReadWriteOnce]
  resources:
    requests:
      storage: 10Gi
  storageClassName: gp3
EOF

# æ£€æŸ¥
kubectl get pvc test-pvc

# æ¸…ç†
kubectl delete pvc test-pvc
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: é›†ç¾¤åˆ›å»ºå¤±è´¥

```bash
# æŸ¥çœ‹ CloudFormation
aws cloudformation describe-stack-events \
  --stack-name eksctl-${CLUSTER_NAME}-cluster \
  --region ${AWS_REGION}

# æ£€æŸ¥ VPC
aws ec2 describe-vpcs --vpc-ids $VPC_ID
```

### é—®é¢˜ 2: æ— æ³•è®¿é—® API Server

**é”™è¯¯:** `dial tcp 10.0.x.x:443: i/o timeout`

**åŸå› :** API çº¯å†…ç½‘è®¿é—®ï¼ˆ`publicAccess: false`ï¼‰

**è§£å†³:**
- ä» VPC å†…éƒ¨éƒ¨ç½²
- æˆ–ä¸´æ—¶å¯ç”¨å…¬ç½‘:
```bash
# ä¿®æ”¹ manifests/cluster/eksctl_cluster_base.yaml
# publicAccess: false â†’ publicAccess: true
```

### é—®é¢˜ 3: Pod æ— æ³•è°ƒåº¦åˆ° app èŠ‚ç‚¹

**åŸå› :** ç¼ºå°‘ Toleration

**è§£å†³:**
```yaml
spec:
  tolerations:
  - key: "workload"
    operator: "Equal"
    value: "user-apps"
    effect: "NoSchedule"
  nodeSelector:
    workload: user-apps
```

### é—®é¢˜ 4: SSH Key ä¸å­˜åœ¨

```bash
# åˆ›å»º
aws ec2 create-key-pair --key-name spider --region ap-southeast-1 \
  --query 'KeyMaterial' --output text > spider.pem
chmod 400 spider.pem
```

### é—®é¢˜ 5: æ•°æ®ç›˜æœªæŒ‚è½½

```bash
# SSH åˆ°èŠ‚ç‚¹
aws ssm start-session --target <instance-id>

# æŸ¥çœ‹ç£ç›˜
lsblk

# æ£€æŸ¥æ—¥å¿—
sudo cat /var/log/spider-node-init.log

# æ‰‹åŠ¨æŒ‚è½½
sudo mkfs -t xfs /dev/xvdb
sudo mount /dev/xvdb /data
```

---

## ğŸ—‘ï¸ æ¸…ç†èµ„æº

### å®Œæ•´æ¸…ç†

```bash
# 1. åˆ é™¤æµ‹è¯•åº”ç”¨
kubectl delete deployment test 2>/dev/null || true
kubectl delete namespace game-2048 2>/dev/null || true

# 2. åˆ é™¤ Load Balancer
kubectl delete ingress --all -A

# 3. åˆ é™¤ PVC
kubectl delete pvc --all -A

# 4. ç­‰å¾…
sleep 60

# 5. åˆ é™¤é›†ç¾¤
eksctl delete cluster --name=${CLUSTER_NAME} --region=${AWS_REGION} --wait
```

### æ¸…ç† Launch Template

```bash
cd terraform/launch-template
terraform destroy
```

### æ¸…ç† VPC

```bash
cd terraform/vpc
terraform destroy
```

---

## ğŸ“Š é¡¹ç›®ç»“æ„

```
eks-cluster-deployment/
â”œâ”€â”€ README.md                    # æœ¬æ–‡æ¡£ï¼ˆå”¯ä¸€æ–‡æ¡£ï¼‰
â”œâ”€â”€ .env.example                 # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 0_setup_env.sh          # ç¯å¢ƒå˜é‡åŠ è½½
â”‚   â”œâ”€â”€ 4_install_eks_cluster.sh            # æ ‡å‡†éƒ¨ç½²
â”‚   â””â”€â”€ 6_install_eks_with_custom_nodegroup.sh  # Launch Template éƒ¨ç½²
â”‚
â”œâ”€â”€ manifests/
â”‚   â”œâ”€â”€ cluster/
â”‚   â”‚   â”œâ”€â”€ eksctl_cluster_template.yaml    # åŸå§‹ï¼ˆä¸¤ä¸ªèŠ‚ç‚¹ç»„ï¼‰
â”‚   â”‚   â”œâ”€â”€ eksctl_cluster_base.yaml        # åŸºç¡€ï¼ˆä»… eks-utilsï¼‰
â”‚   â”‚   â””â”€â”€ eksctl_nodegroup_app.yaml       # app èŠ‚ç‚¹ç»„
â”‚   â”œâ”€â”€ addons/
â”‚   â”‚   â”œâ”€â”€ cluster-autoscaler-rbac.yaml
â”‚   â”‚   â”œâ”€â”€ cluster-autoscaler.yaml
â”‚   â”‚   â”œâ”€â”€ efs-csi-driver.yaml
â”‚   â”‚   â””â”€â”€ s3-csi-driver.yaml
â”‚   â””â”€â”€ examples/
â”‚       â”œâ”€â”€ autoscaler.yaml
â”‚       â”œâ”€â”€ ebs-app.yaml
â”‚       â”œâ”€â”€ efs-app.yaml
â”‚       â””â”€â”€ s3-app.yaml
â”‚
â””â”€â”€ terraform/
    â”œâ”€â”€ vpc/                     # VPC åˆ›å»º
    â”œâ”€â”€ vpc-endpoints/           # VPC Endpoints
    â””â”€â”€ launch-template/         # Launch Template
        â”œâ”€â”€ main.tf
        â”œâ”€â”€ variables.tf
        â”œâ”€â”€ outputs.tf
        â””â”€â”€ terraform.tfvars.spider-example  # Spider ç¤ºä¾‹
```

---

## ğŸ“š å¸¸ç”¨å‘½ä»¤

### é›†ç¾¤ç®¡ç†
```bash
# æŸ¥çœ‹é›†ç¾¤
eksctl get cluster --region=${AWS_REGION}

# æ›´æ–° kubeconfig
aws eks update-kubeconfig --name ${CLUSTER_NAME} --region ${AWS_REGION}

# èŠ‚ç‚¹ç»„
eksctl get nodegroup --cluster=${CLUSTER_NAME} --region=${AWS_REGION}
```

### èŠ‚ç‚¹ç®¡ç†
```bash
# åˆ—å‡ºèŠ‚ç‚¹
kubectl get nodes -o wide

# è¯¦æƒ…
kubectl describe node <node-name>

# èµ„æºä½¿ç”¨
kubectl top nodes
```

### ç›‘æ§
```bash
# Pod èµ„æº
kubectl top pods -A --sort-by=memory

# äº‹ä»¶
kubectl get events -A --sort-by='.lastTimestamp' | tail -20

# æ—¥å¿—
kubectl logs -n kube-system -l app=cluster-autoscaler -f
kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller -f
```

### Launch Template
```bash
# æŸ¥çœ‹
aws ec2 describe-launch-templates --region ${AWS_REGION}

# æ›´æ–°
cd terraform/launch-template
terraform apply

# æ›´æ–°èŠ‚ç‚¹ç»„
eksctl upgrade nodegroup --cluster=${CLUSTER_NAME} --name=app --region=${AWS_REGION}
```

---

## ğŸ†˜ è·å–å¸®åŠ©

### æ–‡æ¡£
- [AWS EKS](https://docs.aws.amazon.com/eks/)
- [eksctl](https://eksctl.io/)
- [Kubernetes](https://kubernetes.io/docs/)
- [Cluster Autoscaler](https://github.com/kubernetes/autoscaler)

### æ’æŸ¥æµç¨‹
1. `kubectl describe pod <pod-name>`
2. `kubectl logs <pod-name>`
3. `kubectl describe node <node-name>`
4. æŸ¥çœ‹ CloudFormation
5. æŸ¥çœ‹ CloudWatch Logs

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### v2.0 (2025-12-09)
- âœ… æ·»åŠ  Launch Template æ”¯æŒ
- âœ… æ”¯æŒè‡ªå®šä¹‰ SSH Keyã€æ•°æ®ç›˜ã€User Data
- âœ… æ·»åŠ  Spider çˆ¬è™«é¡¹ç›®ç¤ºä¾‹
- âœ… ç»Ÿä¸€æ–‡æ¡£ï¼Œåˆ é™¤å†—ä½™æ–‡ä»¶
- âœ… æ›´æ–°æ‰€æœ‰é…ç½®ä¸ºæœ€æ–°ç‰ˆæœ¬

### v1.0 (2025-12-05)
- âœ… åˆå§‹ç‰ˆæœ¬
- âœ… æ··åˆæ¶æ„ï¼ˆIntel + Gravitonï¼‰
- âœ… Cluster Autoscaler
- âœ… AWS Load Balancer Controller
- âœ… EBS/EFS/S3 CSI Driver

---

**ç»´æŠ¤è€…:** Platform Team
**æœ€åæ›´æ–°:** 2025-12-09
**æ–‡æ¡£ç‰ˆæœ¬:** v2.0
